{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e92e839a-d375-4991-9632-13955346affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import xlsxwriter\n",
    "import os\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook'\n",
    "import plotly.express as px\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# @changes from inna\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "91584b18-4524-49a0-adbc-27cd5120e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folderPathTrain, folderPathTest):\n",
    "    print('load new files')\n",
    "    df_categorical = pd.read_excel(f'{folderPathTrain}/TRAIN_CATEGORICAL_METADATA_new.xlsx')\n",
    "    df_matrices = pd.read_csv(f'{folderPathTrain}/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv')\n",
    "    df_quant = pd.read_excel(f'{folderPathTrain}/TRAIN_QUANTITATIVE_METADATA_new.xlsx')\n",
    "    df_solutions = pd.read_excel(f'{folderPathTrain}/TRAINING_SOLUTIONS.xlsx')  \n",
    "    \n",
    "    print('train categorical data count',df_categorical.shape)\n",
    "    print('train quantitative data count',df_quant.shape)\n",
    "    print('train matrices data count',df_matrices.shape)\n",
    "    print('train solutions data count',df_solutions.shape)\n",
    "    \n",
    "    print('load test files')\n",
    "    df_categorical_test = pd.read_excel(f'{folderPathTest}/TEST_CATEGORICAL.xlsx')\n",
    "    df_matrices_test = pd.read_csv(f'{folderPathTest}/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv')\n",
    "    df_quant_test = pd.read_excel(f'{folderPathTest}/TEST_QUANTITATIVE_METADATA.xlsx')\n",
    "\n",
    "    \n",
    "    print('test categorical data count',df_categorical_test.shape)\n",
    "    print('test quantitative data count',df_quant_test.shape)\n",
    "    print('test matrices data count',df_matrices_test.shape)\n",
    "    \n",
    "    return df_categorical,df_matrices,df_quant,df_solutions,df_categorical_test,df_matrices_test,df_quant_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "e040883f-7790-4bfe-9e3e-97075fed55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_data(categorical,matrices,quantitative,solutions=None):\n",
    "    print('joining data frames')\n",
    "    print('categorical data count',categorical.shape)\n",
    "    print('quantitative data count',quantitative.shape)\n",
    "    print('matrices data count',matrices.shape)\n",
    "    cat_quant = pd.merge(categorical, quantitative , on ='participant_id', how ='inner')\n",
    "    cat_quant_mat = pd.merge(cat_quant, matrices , on ='participant_id', how ='inner')\n",
    "    if isinstance(solutions, pd.DataFrame):\n",
    "        cat_quant_mat_sols = pd.merge(cat_quant_mat, solutions , on ='participant_id', how ='inner')\n",
    "        print('solutions data count',solutions.shape)\n",
    "        return cat_quant_mat_sols\n",
    "    else:    \n",
    "        return cat_quant_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "e091d34b-b925-4622-9995-73a2eff9ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_classifer(objective = 'binary:logistic', max_depth=5,learning_rate=0.1,n_estimators=100):\n",
    "    print('xgboost_classifer')\n",
    "    # Initialize the base classifier\n",
    "    classifier = XGBClassifier(objective=objective, \\\n",
    "                               n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth)\n",
    "    multioutput_classifier = MultiOutputClassifier(classifier)\n",
    "    return multioutput_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "703bef88-dd2d-4dfd-b0dc-900b2f7f0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,X_test):\n",
    "    print('predict with the model')\n",
    "    X_test_data  = X_test.drop(columns = ['participant_id'] )\n",
    "    y_pred = model.predict(X_test_data)\n",
    "    predictions_df = pd.DataFrame(\n",
    "        y_pred,\n",
    "        columns=['ADHD_Outcome', 'Sex_F']\n",
    "    )\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "c685473c-278b-46cd-96d6-d551b59ed902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(y_test,y_pred):\n",
    "    print('calculate score with prediction vs true values')\n",
    "    y_test_results  = y_test.drop(columns = ['participant_id'] )\n",
    "    accuracy = accuracy_score(y_test_results, y_pred)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "c6fde7e0-0a6f-4792-acfe-5da22cedf397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_data(X,Y):\n",
    "    print('split the train and test data')\n",
    "    X_train_data, X_test_data, y_train_data, y_test_data = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    return X_train_data, X_test_data, y_train_data, y_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "d2f1be46-f7fc-4b14-9f48-e3bd237e6c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_output_accuracy(y_true, y_pred):\n",
    "    print('multi_output_accuracy')\n",
    "    # Ensure y_true and y_pred are NumPy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    # Compute accuracy for each target variable and return the mean\n",
    "    return np.mean([accuracy_score(y_true[:, i], y_pred[:, i]) for i in range(y_true.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "c5118ade-a2dc-4205-bceb-211daaf6ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cross_validation(X,Y,model):\n",
    "    # Perform cross-validation on the training data\n",
    "    X_train_cv  = X.drop(columns = ['participant_id'] )\n",
    "    y_train_cv  = Y.drop(columns = ['participant_id'] )\n",
    "    # Create a scorer using scikit-learn's make_scorer\n",
    "    multi_output_scorer = make_scorer(multi_output_accuracy)\n",
    "    cv_scores = cross_val_score(model, X_train_cv, y_train_cv, cv=5, scoring=multi_output_scorer)\n",
    "    \n",
    "    # Output the cross-validation results\n",
    "    print(\"Cross-validation scores for each fold:\", cv_scores)\n",
    "    print(\"Mean CV score:\", f'Mean Accuracy: {np.mean(cv_scores) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "a2ebed42-c23c-443b-ad4b-c18c54c511fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_matrices_data(df_matrices_new,n_components = 1000):\n",
    "    print('starting pca analysis')\n",
    "    print(df_matrices_new.shape)\n",
    "    df_matrices_for_pca = df_matrices_new.drop(columns = ['participant_id'] )\n",
    "    # PCA df with index preserved as index\n",
    "    \n",
    "    original_index = df_matrices_for_pca.index\n",
    "    \n",
    "    # 1. Standardize the data (excluding the first column)\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(df_matrices_for_pca)\n",
    "    \n",
    "    # 2. Apply PCA\n",
    "    # Start with a smaller number of components for exploration\n",
    "    pca = PCA(n_components=n_components)  # Adjust based on your needs\n",
    "    pca_result = pca.fit_transform(scaled_data)\n",
    "    \n",
    "    # 3. Analyze explained variance\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    cumulative_variance = np.cumsum(explained_variance)\n",
    "    \n",
    "    # 5. Find number of components for desired variance (e.g., 80%)\n",
    "    n_components_80 = np.argmax(cumulative_variance >= 0.8) + 1\n",
    "    print(f\"Number of components needed for 80% variance: {n_components_80}\")\n",
    "    \n",
    "    # 6. Re-run PCA with the optimal number of components\n",
    "    pca_final = PCA(n_components=n_components_80)\n",
    "    pca_result_final = pca_final.fit_transform(scaled_data)\n",
    "    \n",
    "    # 7. Create a DataFrame with the PCA results\n",
    "    pca_df = pd.DataFrame(\n",
    "        data=pca_result_final,\n",
    "        columns=[f'PC{i+1}' for i in range(n_components_80)],\n",
    "        index=original_index\n",
    "    )\n",
    "\n",
    "    # 8 \n",
    "    pca_df['participant_id'] = df_matrices_new['participant_id']\n",
    "    \n",
    "    return pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "d493e54b-c66d-4853-be1a-fe54e93d79bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_quant_data(df_quant_new):\n",
    "    print('starting quant data scaling')\n",
    "    df_quant_scaled_dropped = df_quant_new.drop(columns = ['participant_id'] )\n",
    "    df_quant_scaled_dropped = pd.DataFrame(df_quant_scaled_dropped)\n",
    "    scaler = StandardScaler()\n",
    "    df_quant_scaled = scaler.fit_transform(df_quant_scaled_dropped)\n",
    "    df_quant_scaled = pd.DataFrame(df_quant_scaled)\n",
    "    df_quant_scaled['participant_id'] = df_quant_new['participant_id']\n",
    "\n",
    "    #select specific columns only for classifier\n",
    "    df_quant_scaled_selected = df_quant_scaled.iloc[:,4:]\n",
    "    return df_quant_scaled_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "02fb1674-717c-4fc9-acb5-01dd4eb46f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_categorical_data(df_categorical_new):\n",
    "    print('starting categorical data encoding')\n",
    "    # One-Hot Encoding (nominal)\n",
    "    # encoder with fixed categoried added for fixing unknown data in train vs test\n",
    "    onehot_encoder = OneHotEncoder(categories = [[0,1,2,3]], handle_unknown='ignore', sparse_output=False, drop='first') #drop first to prevent multicollinearity\n",
    "    #nominal_cols = ['MRI_Track_Scan_Location', 'Basic_Demos_Study_Site', 'PreInt_Demos_Fam_Child_Race', 'PreInt_Demos_Fam_Child_Ethnicity']\n",
    "    nominal_cols = ['PreInt_Demos_Fam_Child_Ethnicity']\n",
    "\n",
    "    \n",
    "    onehot_encoded = onehot_encoder.fit_transform(df_categorical_new[nominal_cols])\n",
    "    onehot_df = pd.DataFrame(onehot_encoded, columns=onehot_encoder.get_feature_names_out(nominal_cols))\n",
    "    encoded_df = pd.concat([df_categorical_new, onehot_df], axis=1)\n",
    "    encoded_df = encoded_df.drop(nominal_cols, axis=1)\n",
    "    \n",
    "    onehot_encoder = OneHotEncoder(categories = [[0,1,2,3,4,5,6,7,8,9,10,11]], handle_unknown='ignore', sparse_output=False, drop='first') #drop first to prevent multicollinearity\n",
    "    nominal_cols = ['PreInt_Demos_Fam_Child_Race']\n",
    "    onehot_encoded = onehot_encoder.fit_transform(df_categorical_new[nominal_cols])\n",
    "    onehot_df = pd.DataFrame(onehot_encoded, columns=onehot_encoder.get_feature_names_out(nominal_cols))\n",
    "    encoded_df = pd.concat([encoded_df, onehot_df], axis=1)\n",
    "    encoded_df = encoded_df.drop(nominal_cols, axis=1)    \n",
    "\n",
    "    onehot_encoder = OneHotEncoder(categories = [[0,1,2,3,4]], handle_unknown='ignore', sparse_output=False, drop='first') #drop first to prevent multicollinearity\n",
    "    nominal_cols = ['MRI_Track_Scan_Location']\n",
    "    onehot_encoded = onehot_encoder.fit_transform(df_categorical_new[nominal_cols])\n",
    "    onehot_df = pd.DataFrame(onehot_encoded, columns=onehot_encoder.get_feature_names_out(nominal_cols))\n",
    "    encoded_df = pd.concat([encoded_df, onehot_df], axis=1)\n",
    "    encoded_df = encoded_df.drop(nominal_cols, axis=1)  \n",
    "    \n",
    "    # Handle NaN and 0.0 values (imputation example)\n",
    "    encoded_df['Barratt_Barratt_P1_Edu'] = encoded_df['Barratt_Barratt_P1_Edu'].fillna(encoded_df['Barratt_Barratt_P1_Edu'].median())\n",
    "    encoded_df['Barratt_Barratt_P2_Edu'] = encoded_df['Barratt_Barratt_P2_Edu'].fillna(encoded_df['Barratt_Barratt_P2_Edu'].median())\n",
    "    \n",
    "    encoded_df['Barratt_Barratt_P1_Edu'] = encoded_df['Barratt_Barratt_P1_Edu'].replace(0.0, encoded_df['Barratt_Barratt_P1_Edu'].median())\n",
    "    encoded_df['Barratt_Barratt_P2_Edu'] = encoded_df['Barratt_Barratt_P2_Edu'].replace(0.0, encoded_df['Barratt_Barratt_P2_Edu'].median())\n",
    "\n",
    "    # Ordinal Encoding (ordinal)\n",
    "    ordinal_encoder = OrdinalEncoder(categories=[[ 3, 6, 9, 12, 15, 18, 21],[ 3, 6, 9, 12, 15, 18, 21] ])\n",
    "    ordinal_cols = ['Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P2_Edu']\n",
    "    encoded_df[ordinal_cols] = ordinal_encoder.fit_transform(encoded_df[ordinal_cols])\n",
    "\n",
    "    # Handle NaN and 0.0 values (imputation example)\n",
    "    encoded_df['Barratt_Barratt_P1_Occ'] = encoded_df['Barratt_Barratt_P1_Occ'].fillna(encoded_df['Barratt_Barratt_P1_Occ'].median())\n",
    "    encoded_df['Barratt_Barratt_P2_Occ'] = encoded_df['Barratt_Barratt_P2_Occ'].fillna(encoded_df['Barratt_Barratt_P2_Occ'].median())\n",
    "    encoded_df['Barratt_Barratt_P1_Occ'] = encoded_df['Barratt_Barratt_P1_Occ'].replace(0.0, encoded_df['Barratt_Barratt_P1_Occ'].median())\n",
    "    encoded_df['Barratt_Barratt_P2_Occ'] = encoded_df['Barratt_Barratt_P2_Occ'].replace(0.0, encoded_df['Barratt_Barratt_P2_Occ'].median())\n",
    "    \n",
    "    # Ordinal Encoding (ordinal)\n",
    "    ordinal_encoder = OrdinalEncoder(categories=[[0, 5, 10, 15, 20, 25, 30, 35, 40, 45], [0, 5, 10, 15, 20, 25, 30, 35, 40, 45]])\n",
    "    ordinal_cols = ['Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Occ']\n",
    "    encoded_df[ordinal_cols] = ordinal_encoder.fit_transform(encoded_df[ordinal_cols])\n",
    "\n",
    "    encoded_df_modified = encoded_df.drop(columns = ['Basic_Demos_Enroll_Year'])\n",
    "    return encoded_df_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "7277fc20-0e72-40d7-8b8e-c3cbec6adf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_train(X = None, Y =None,max_depth= None,learning_rate = None,n_estimators = None):\n",
    "    print('starting training')\n",
    "    print('setting tuning params')\n",
    "    classifier = xgboost_classifer(max_depth=max_depth,learning_rate=learning_rate,n_estimators=n_estimators)\n",
    "    print('splitting to test and train')\n",
    "    X_train_data, X_test_data, y_train_data, y_test_data = split_train_data(X, Y)\n",
    "    \n",
    "    print('training the model')\n",
    "    X_train  = X_train_data.drop(columns = ['participant_id'] )\n",
    "    y_train  = y_train_data.drop(columns = ['participant_id'] )\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('setting cross validation classifier with tuning params')\n",
    "    classifier_cv = xgboost_classifer(max_depth=max_depth,learning_rate=learning_rate,n_estimators=n_estimators)\n",
    "    print('start cross validation')\n",
    "    do_cross_validation(X,Y,classifier_cv)\n",
    "    \n",
    "    print('check accuracy')\n",
    "    y_pred = predict(classifier,X_test_data)\n",
    "    print('calculate score')\n",
    "    accuracy = calculate_score(y_test_data,y_pred)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "cb7b6290-0c8a-4e49-92dc-9f1e7b43e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_test(classifier = None,X = None):\n",
    "    print('start testing')\n",
    "    Y = predict(classifier,X)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c85c6-d929-40f6-b84e-444e006dff0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ebf7e6-cec8-4b2f-8e46-bb4735d36503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eaf6668-5462-4f26-a954-441a810fc145",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "2fc71f50-a4cf-4da3-b432-6bd5735c5d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load new files\n",
      "train categorical data count (1213, 10)\n",
      "train quantitative data count (1213, 19)\n",
      "train matrices data count (1213, 19901)\n",
      "train solutions data count (1213, 3)\n",
      "load test files\n",
      "test categorical data count (304, 10)\n",
      "test quantitative data count (304, 19)\n",
      "test matrices data count (304, 19901)\n"
     ]
    }
   ],
   "source": [
    "folderPathTrain, folderPathTest = 'Datafiles/TRAIN_NEW/' , 'Datafiles/TEST/'\n",
    "df_categorical_train,df_matrices_train,df_quant_train,df_solutions_train,df_categorical_test,df_matrices_test,df_quant_test = load_data(folderPathTrain, folderPathTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "692f0a49-d8ba-45ca-9399-be5c62be30e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting pca analysis\n",
      "(1213, 19901)\n",
      "Number of components needed for 80% variance: 464\n",
      "starting quant data scaling\n",
      "starting categorical data encoding\n"
     ]
    }
   ],
   "source": [
    "pca_df_train = transform_matrices_data(df_matrices_train,n_components = 1000)\n",
    "quant_df_train = transform_quant_data(df_quant_train)\n",
    "cat_df_train = transform_categorical_data(df_categorical_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "36e31936-f28f-4435-9499-9a5f5587d42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca train (1213, 465)\n",
      "cat train (1213, 24)\n",
      "quant train (1213, 15)\n"
     ]
    }
   ],
   "source": [
    "print('pca train', pca_df_train.shape)\n",
    "print('cat train', cat_df_train.shape)\n",
    "print('quant train', quant_df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "7460ff98-62e3-46da-8457-5cc1faffd4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joining data frames\n",
      "categorical data count (1213, 24)\n",
      "quantitative data count (1213, 15)\n",
      "matrices data count (1213, 465)\n",
      "solutions data count (1213, 3)\n"
     ]
    }
   ],
   "source": [
    "# using df_matrices_train instead of pca_df_train\n",
    "# reverting to use new pca\n",
    "joined_training_data = join_data(cat_df_train,pca_df_train,quant_df_train,df_solutions_train)\n",
    "X = joined_training_data.drop(columns = ['ADHD_Outcome', 'Sex_F'] )\n",
    "Y = joined_training_data[['participant_id','ADHD_Outcome', 'Sex_F']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "5e98fd11-ac76-4320-aa9d-cf38c73373c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1213, 502)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "a4b1e837-581f-4a52-92f0-e91ceb493560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participant_id    1213\n",
       "ADHD_Outcome      1213\n",
       "Sex_F             1213\n",
       "dtype: int64"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103b0895-45ec-4e8e-97b0-a3121181d4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "d41c5437-55b9-4663-a914-93fab0edfc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "setting tuning params\n",
      "xgboost_classifer\n",
      "splitting to test and train\n",
      "split the train and test data\n",
      "training the model\n",
      "setting cross validation classifier with tuning params\n",
      "xgboost_classifer\n",
      "start cross validation\n",
      "multi_output_accuracy\n",
      "multi_output_accuracy\n",
      "multi_output_accuracy\n",
      "multi_output_accuracy\n",
      "multi_output_accuracy\n",
      "Cross-validation scores for each fold: [0.70164609 0.77777778 0.70164609 0.77066116 0.70867769]\n",
      "Mean CV score: Mean Accuracy: 73.21%\n",
      "check accuracy\n",
      "predict with the model\n",
      "calculate score\n",
      "calculate score with prediction vs true values\n",
      "Accuracy: 57.20%\n"
     ]
    }
   ],
   "source": [
    "classifier_trained = xgboost_train(X = X, Y =Y,max_depth= 5,learning_rate = 0.1,n_estimators = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84a825c-de80-427c-b688-ea04164e758a",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "a64d72b6-5ec5-430a-ab40-224140504761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting pca analysis\n",
      "(304, 19901)\n",
      "Number of components needed for 80% variance: 162\n",
      "starting quant data scaling\n",
      "starting categorical data encoding\n"
     ]
    }
   ],
   "source": [
    "pca_df_test = transform_matrices_data(df_matrices_test,n_components = 200)\n",
    "quant_df_test = transform_quant_data(df_quant_test)\n",
    "cat_df_test = transform_categorical_data(df_categorical_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "97d41d17-98b5-4131-9cad-c4d74b479059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca test (304, 163)\n",
      "cat test (304, 24)\n",
      "quant test (304, 15)\n"
     ]
    }
   ],
   "source": [
    "print('pca test', pca_df_test.shape)\n",
    "print('cat test', cat_df_test.shape)\n",
    "print('quant test', quant_df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "49fdbb32-b93b-405b-bf98-96858ad89aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_test.rename(columns={'MRI_Track_Scan_Location_1': 'MRI_Track_Scan_Location_1.0'}, inplace=True)\n",
    "cat_df_test.rename(columns={'MRI_Track_Scan_Location_2': 'MRI_Track_Scan_Location_2.0'}, inplace=True)\n",
    "cat_df_test.rename(columns={'MRI_Track_Scan_Location_3': 'MRI_Track_Scan_Location_3.0'}, inplace=True)\n",
    "cat_df_test.rename(columns={'MRI_Track_Scan_Location_4': 'MRI_Track_Scan_Location_4.0'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "7be0eb8f-c52a-46e0-a697-d6aac72251fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joining data frames\n",
      "categorical data count (304, 24)\n",
      "quantitative data count (304, 15)\n",
      "matrices data count (304, 163)\n"
     ]
    }
   ],
   "source": [
    "# using df_matrices_new instead of pca_df_test\n",
    "# USING new PCA\n",
    "X_test = join_data(cat_df_test,pca_df_test,quant_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "9ad12fe9-7577-4931-bf76-7a6a8a981f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "6ee29f46-acc1-474a-ae21-6aecae707834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "b0888fed-0526-4d0b-b085-68c68b28cee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 200)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "ef39d740-47d2-4f38-9cb6-bf7df02c1078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of train vs test cols in list1 but not in list2: ['PC291', 'PC187', 'PC302', 'PC224', 'PC186', 'PC306', 'PC248', 'PC259', 'PC339', 'PC246', 'PC413', 'PC197', 'PC298', 'PC452', 'PC313', 'PC431', 'PC435', 'PC244', 'PC432', 'PC196', 'PC373', 'PC185', 'PC304', 'PC173', 'PC216', 'PC180', 'PC222', 'PC404', 'PC419', 'PC437', 'PC384', 'PC387', 'PC402', 'PC407', 'PC172', 'PC409', 'PC355', 'PC174', 'PC332', 'PC426', 'PC270', 'PC312', 'PC190', 'PC212', 'PC379', 'PC361', 'PC240', 'PC393', 'PC252', 'PC199', 'PC345', 'PC434', 'PC280', 'PC165', 'PC211', 'PC198', 'PC395', 'PC269', 'PC350', 'PC411', 'PC399', 'PC241', 'PC305', 'PC414', 'PC203', 'PC354', 'PC370', 'PC381', 'PC403', 'PC208', 'PC410', 'PC342', 'PC254', 'PC296', 'PC183', 'PC464', 'PC319', 'PC215', 'PC317', 'PC445', 'PC265', 'PC329', 'PC427', 'PC334', 'PC438', 'PC358', 'PC463', 'PC325', 'PC235', 'PC430', 'PC353', 'PC453', 'PC193', 'PC289', 'PC314', 'PC367', 'PC285', 'PC425', 'PC300', 'PC310', 'PC182', 'PC417', 'PC376', 'PC459', 'PC231', 'PC365', 'PC429', 'PC257', 'PC266', 'PC447', 'PC206', 'PC451', 'PC324', 'PC380', 'PC346', 'PC274', 'PC239', 'PC167', 'PC273', 'PC400', 'PC191', 'PC385', 'PC255', 'PC440', 'PC184', 'PC423', 'PC398', 'PC242', 'PC396', 'PC251', 'PC290', 'PC292', 'PC261', 'PC307', 'PC299', 'PC258', 'PC169', 'PC333', 'PC213', 'PC444', 'PC181', 'PC284', 'PC227', 'PC320', 'PC204', 'PC218', 'PC378', 'PC275', 'PC341', 'PC200', 'PC375', 'PC344', 'PC253', 'PC433', 'PC364', 'PC237', 'PC262', 'PC372', 'PC267', 'PC268', 'PC188', 'PC256', 'PC303', 'PC422', 'PC210', 'PC331', 'PC249', 'PC232', 'PC338', 'PC412', 'PC315', 'PC318', 'PC295', 'PC276', 'PC374', 'PC363', 'PC446', 'PC217', 'PC233', 'PC362', 'PC264', 'PC328', 'PC168', 'PC349', 'PC293', 'PC195', 'PC458', 'PC271', 'PC260', 'PC301', 'PC250', 'PC175', 'PC311', 'PC277', 'PC166', 'PC454', 'PC455', 'PC282', 'PC229', 'PC368', 'PC448', 'PC356', 'PC221', 'PC456', 'PC369', 'PC397', 'PC382', 'PC164', 'PC209', 'PC420', 'PC327', 'PC340', 'PC283', 'PC294', 'PC189', 'PC170', 'PC207', 'PC336', 'PC389', 'PC406', 'PC234', 'PC424', 'PC194', 'PC179', 'PC281', 'PC347', 'PC436', 'PC201', 'PC418', 'PC343', 'PC348', 'PC450', 'PC443', 'PC316', 'PC460', 'PC287', 'PC205', 'PC297', 'PC330', 'PC202', 'PC359', 'PC245', 'PC366', 'PC449', 'PC416', 'PC390', 'PC360', 'PC401', 'PC278', 'PC383', 'PC441', 'PC408', 'PC462', 'PC386', 'PC351', 'PC223', 'PC357', 'PC192', 'PC322', 'PC243', 'PC230', 'PC263', 'PC457', 'PC388', 'PC352', 'PC225', 'PC226', 'PC286', 'PC171', 'PC219', 'PC177', 'PC228', 'PC415', 'PC321', 'PC176', 'PC163', 'PC394', 'PC421', 'PC214', 'PC461', 'PC439', 'PC236', 'PC323', 'PC371', 'PC309', 'PC337', 'PC288', 'PC442', 'PC272', 'PC279', 'PC377', 'PC392', 'PC326', 'PC428', 'PC220', 'PC238', 'PC405', 'PC308', 'PC247', 'PC178', 'PC335', 'PC391']\n"
     ]
    }
   ],
   "source": [
    "set1 = set(list(X.columns))\n",
    "set2 = set(list(X_test.columns))\n",
    "difference1 = list(set1 - set2)\n",
    "print(f\"Comparison of train vs test cols in list1 but not in list2: {difference1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "6bb19c53-03a0-46c7-8b2a-22c68ad33deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start testing\n",
      "predict with the model\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['Basic_Demos_Study_Site', 'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu', 'Barratt_Barratt_P2_Occ', 'PreInt_Demos_Fam_Child_Ethnicity_1.0', 'PreInt_Demos_Fam_Child_Ethnicity_2.0', 'PreInt_Demos_Fam_Child_Ethnicity_3.0', 'PreInt_Demos_Fam_Child_Race_1.0', 'PreInt_Demos_Fam_Child_Race_2.0', 'PreInt_Demos_Fam_Child_Race_3.0', 'PreInt_Demos_Fam_Child_Race_4.0', 'PreInt_Demos_Fam_Child_Race_5.0', 'PreInt_Demos_Fam_Child_Race_6.0', 'PreInt_Demos_Fam_Child_Race_7.0', 'PreInt_Demos_Fam_Child_Race_8.0', 'PreInt_Demos_Fam_Child_Race_9.0', 'PreInt_Demos_Fam_Child_Race_10.0', 'PreInt_Demos_Fam_Child_Race_11.0', 'MRI_Track_Scan_Location_1.0', 'MRI_Track_Scan_Location_2.0', 'MRI_Track_Scan_Location_3.0', 'MRI_Track_Scan_Location_4.0', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', 'PC1'] ['Basic_Demos_Study_Site', 'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu', 'Barratt_Barratt_P2_Occ', 'PreInt_Demos_Fam_Child_Ethnicity_1.0', 'PreInt_Demos_Fam_Child_Ethnicity_2.0', 'PreInt_Demos_Fam_Child_Ethnicity_3.0', 'PreInt_Demos_Fam_Child_Race_1.0', 'PreInt_Demos_Fam_Child_Race_2.0', 'PreInt_Demos_Fam_Child_Race_3.0', 'PreInt_Demos_Fam_Child_Race_4.0', 'PreInt_Demos_Fam_Child_Race_5.0', 'PreInt_Demos_Fam_Child_Race_6.0', 'PreInt_Demos_Fam_Child_Race_7.0', 'PreInt_Demos_Fam_Child_Race_8.0', 'PreInt_Demos_Fam_Child_Race_9.0', 'PreInt_Demos_Fam_Child_Race_10.0', 'PreInt_Demos_Fam_Child_Race_11.0', 'MRI_Track_Scan_Location_1.0', 'MRI_Track_Scan_Location_2.0', 'MRI_Track_Scan_Location_3.0', 'MRI_Track_Scan_Location_4.0', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18', 'PC19', 'PC20', 'PC21', 'PC22', 'PC23', 'PC24', 'PC25', 'PC26', 'PC27', 'PC28', 'PC29', 'PC30', 'PC31', 'PC32', 'PC33', 'PC34', 'PC35', 'PC36', 'PC37', 'PC38', 'PC39', 'PC40', 'PC41', 'PC42', 'PC43', 'PC44', 'PC45', 'PC46', 'PC47', 'PC48', 'PC49', 'PC50', 'PC51', 'PC52', 'PC53', 'PC54', 'PC55', 'PC56', 'PC57', 'PC58', 'PC59', 'PC60', 'PC61', 'PC62', 'PC63', 'PC64', 'PC65', 'PC66', 'PC67', 'PC68', 'PC69', 'PC70', 'PC71', 'PC72', 'PC73', 'PC74', 'PC75', 'PC76', 'PC77', 'PC78', 'PC79', 'PC80', 'PC81', 'PC82', 'PC83', 'PC84', 'PC85', 'PC86', 'PC87', 'PC88', 'PC89', 'PC90', 'PC91', 'PC92', 'PC93', 'PC94', 'PC95', 'PC96', 'PC97', 'PC98', 'PC99', 'PC100', 'PC101', 'PC102', 'PC103', 'PC104', 'PC105', 'PC106', 'PC107', 'PC108', 'PC109', 'PC110', 'PC111', 'PC112', 'PC113', 'PC114', 'PC115', 'PC116', 'PC117', 'PC118', 'PC119', 'PC120', 'PC121', 'PC122', 'PC123', 'PC124', 'PC125', 'PC126', 'PC127', 'PC128', 'PC129', 'PC130', 'PC131', 'PC132', 'PC133', 'PC134', 'PC135', 'PC136', 'PC137', 'PC138', 'PC139', 'PC140', 'PC141', 'PC142', 'PC143', 'PC144', 'PC145', 'PC146', 'PC147', 'PC148', 'PC149', 'PC150', 'PC151', 'PC152', 'PC153', 'PC154', 'PC155', 'PC156', 'PC157', 'PC158', 'PC159', 'PC160', 'PC161', 'PC162']\ntraining data did not have the following fields: PC63, PC84, PC158, PC134, PC101, PC142, PC40, PC77, PC76, PC88, PC107, PC104, PC58, PC105, PC154, PC46, PC11, PC8, PC33, PC42, PC86, PC89, PC129, PC12, PC36, PC115, PC30, PC102, PC110, PC69, PC82, PC93, PC160, PC146, PC15, PC34, PC41, PC147, PC50, PC66, PC119, PC61, PC78, PC90, PC49, PC96, PC144, PC28, PC44, PC141, PC22, PC71, PC118, PC7, PC126, PC5, PC14, PC127, PC73, PC43, PC23, PC57, PC74, PC123, PC161, PC100, PC128, PC122, PC97, PC10, PC111, PC65, PC60, PC48, PC125, PC32, PC131, PC47, PC94, PC109, PC151, PC9, PC54, PC159, PC20, PC155, PC64, PC150, PC72, PC132, PC140, PC53, PC87, PC143, PC2, PC52, PC137, PC29, PC59, PC148, PC25, PC80, PC95, PC156, PC116, PC92, PC145, PC153, PC17, PC38, PC139, PC35, PC79, PC26, PC21, PC68, PC117, PC133, PC152, PC18, PC91, PC99, PC13, PC83, PC108, PC120, PC138, PC24, PC6, PC162, PC135, PC113, PC19, PC121, PC81, PC67, PC149, PC51, PC75, PC124, PC157, PC103, PC70, PC55, PC114, PC45, PC106, PC3, PC98, PC112, PC4, PC39, PC136, PC85, PC37, PC62, PC27, PC130, PC16, PC31, PC56",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[363], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mxgboost_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mclassifier_trained\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[342], line 3\u001b[0m, in \u001b[0;36mxgboost_test\u001b[0;34m(classifier, X)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mxgboost_test\u001b[39m(classifier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart testing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     Y \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Y\n",
      "Cell \u001b[0;32mIn[333], line 4\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(model, X_test)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict with the model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m X_test_data  \u001b[38;5;241m=\u001b[39m X_test\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparticipant_id\u001b[39m\u001b[38;5;124m'\u001b[39m] )\n\u001b[0;32m----> 4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m predictions_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m      6\u001b[0m     y_pred,\n\u001b[1;32m      7\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mADHD_Outcome\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex_F\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions_df\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datathon25/lib/python3.12/site-packages/sklearn/multioutput.py:306\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe base estimator should implement a predict method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 306\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimators_\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(y)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datathon25/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datathon25/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datathon25/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datathon25/lib/python3.12/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datathon25/lib/python3.12/site-packages/xgboost/sklearn.py:1633\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m   1625\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1626\u001b[0m     X: ArrayLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1630\u001b[0m     iteration_range: Optional[IterationRange] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1631\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[1;32m   1632\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[0;32m-> 1633\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1639\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1640\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[1;32m   1641\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datathon25/lib/python3.12/site-packages/xgboost/sklearn.py:1248\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1248\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1256\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[1;32m   1257\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datathon25/lib/python3.12/site-packages/xgboost/core.py:2514\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[0;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[1;32m   2512\u001b[0m     data, fns, _ \u001b[38;5;241m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[1;32m   2513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[0;32m-> 2514\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data) \u001b[38;5;129;01mor\u001b[39;00m _is_tuple(data):\n\u001b[1;32m   2516\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/datathon25/lib/python3.12/site-packages/xgboost/core.py:3079\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[0;34m(self, feature_names)\u001b[0m\n\u001b[1;32m   3073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m my_missing:\n\u001b[1;32m   3074\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   3075\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3076\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m my_missing)\n\u001b[1;32m   3077\u001b[0m     )\n\u001b[0;32m-> 3079\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, feature_names))\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['Basic_Demos_Study_Site', 'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu', 'Barratt_Barratt_P2_Occ', 'PreInt_Demos_Fam_Child_Ethnicity_1.0', 'PreInt_Demos_Fam_Child_Ethnicity_2.0', 'PreInt_Demos_Fam_Child_Ethnicity_3.0', 'PreInt_Demos_Fam_Child_Race_1.0', 'PreInt_Demos_Fam_Child_Race_2.0', 'PreInt_Demos_Fam_Child_Race_3.0', 'PreInt_Demos_Fam_Child_Race_4.0', 'PreInt_Demos_Fam_Child_Race_5.0', 'PreInt_Demos_Fam_Child_Race_6.0', 'PreInt_Demos_Fam_Child_Race_7.0', 'PreInt_Demos_Fam_Child_Race_8.0', 'PreInt_Demos_Fam_Child_Race_9.0', 'PreInt_Demos_Fam_Child_Race_10.0', 'PreInt_Demos_Fam_Child_Race_11.0', 'MRI_Track_Scan_Location_1.0', 'MRI_Track_Scan_Location_2.0', 'MRI_Track_Scan_Location_3.0', 'MRI_Track_Scan_Location_4.0', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', 'PC1'] ['Basic_Demos_Study_Site', 'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu', 'Barratt_Barratt_P2_Occ', 'PreInt_Demos_Fam_Child_Ethnicity_1.0', 'PreInt_Demos_Fam_Child_Ethnicity_2.0', 'PreInt_Demos_Fam_Child_Ethnicity_3.0', 'PreInt_Demos_Fam_Child_Race_1.0', 'PreInt_Demos_Fam_Child_Race_2.0', 'PreInt_Demos_Fam_Child_Race_3.0', 'PreInt_Demos_Fam_Child_Race_4.0', 'PreInt_Demos_Fam_Child_Race_5.0', 'PreInt_Demos_Fam_Child_Race_6.0', 'PreInt_Demos_Fam_Child_Race_7.0', 'PreInt_Demos_Fam_Child_Race_8.0', 'PreInt_Demos_Fam_Child_Race_9.0', 'PreInt_Demos_Fam_Child_Race_10.0', 'PreInt_Demos_Fam_Child_Race_11.0', 'MRI_Track_Scan_Location_1.0', 'MRI_Track_Scan_Location_2.0', 'MRI_Track_Scan_Location_3.0', 'MRI_Track_Scan_Location_4.0', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', 'PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11', 'PC12', 'PC13', 'PC14', 'PC15', 'PC16', 'PC17', 'PC18', 'PC19', 'PC20', 'PC21', 'PC22', 'PC23', 'PC24', 'PC25', 'PC26', 'PC27', 'PC28', 'PC29', 'PC30', 'PC31', 'PC32', 'PC33', 'PC34', 'PC35', 'PC36', 'PC37', 'PC38', 'PC39', 'PC40', 'PC41', 'PC42', 'PC43', 'PC44', 'PC45', 'PC46', 'PC47', 'PC48', 'PC49', 'PC50', 'PC51', 'PC52', 'PC53', 'PC54', 'PC55', 'PC56', 'PC57', 'PC58', 'PC59', 'PC60', 'PC61', 'PC62', 'PC63', 'PC64', 'PC65', 'PC66', 'PC67', 'PC68', 'PC69', 'PC70', 'PC71', 'PC72', 'PC73', 'PC74', 'PC75', 'PC76', 'PC77', 'PC78', 'PC79', 'PC80', 'PC81', 'PC82', 'PC83', 'PC84', 'PC85', 'PC86', 'PC87', 'PC88', 'PC89', 'PC90', 'PC91', 'PC92', 'PC93', 'PC94', 'PC95', 'PC96', 'PC97', 'PC98', 'PC99', 'PC100', 'PC101', 'PC102', 'PC103', 'PC104', 'PC105', 'PC106', 'PC107', 'PC108', 'PC109', 'PC110', 'PC111', 'PC112', 'PC113', 'PC114', 'PC115', 'PC116', 'PC117', 'PC118', 'PC119', 'PC120', 'PC121', 'PC122', 'PC123', 'PC124', 'PC125', 'PC126', 'PC127', 'PC128', 'PC129', 'PC130', 'PC131', 'PC132', 'PC133', 'PC134', 'PC135', 'PC136', 'PC137', 'PC138', 'PC139', 'PC140', 'PC141', 'PC142', 'PC143', 'PC144', 'PC145', 'PC146', 'PC147', 'PC148', 'PC149', 'PC150', 'PC151', 'PC152', 'PC153', 'PC154', 'PC155', 'PC156', 'PC157', 'PC158', 'PC159', 'PC160', 'PC161', 'PC162']\ntraining data did not have the following fields: PC63, PC84, PC158, PC134, PC101, PC142, PC40, PC77, PC76, PC88, PC107, PC104, PC58, PC105, PC154, PC46, PC11, PC8, PC33, PC42, PC86, PC89, PC129, PC12, PC36, PC115, PC30, PC102, PC110, PC69, PC82, PC93, PC160, PC146, PC15, PC34, PC41, PC147, PC50, PC66, PC119, PC61, PC78, PC90, PC49, PC96, PC144, PC28, PC44, PC141, PC22, PC71, PC118, PC7, PC126, PC5, PC14, PC127, PC73, PC43, PC23, PC57, PC74, PC123, PC161, PC100, PC128, PC122, PC97, PC10, PC111, PC65, PC60, PC48, PC125, PC32, PC131, PC47, PC94, PC109, PC151, PC9, PC54, PC159, PC20, PC155, PC64, PC150, PC72, PC132, PC140, PC53, PC87, PC143, PC2, PC52, PC137, PC29, PC59, PC148, PC25, PC80, PC95, PC156, PC116, PC92, PC145, PC153, PC17, PC38, PC139, PC35, PC79, PC26, PC21, PC68, PC117, PC133, PC152, PC18, PC91, PC99, PC13, PC83, PC108, PC120, PC138, PC24, PC6, PC162, PC135, PC113, PC19, PC121, PC81, PC67, PC149, PC51, PC75, PC124, PC157, PC103, PC70, PC55, PC114, PC45, PC106, PC3, PC98, PC112, PC4, PC39, PC136, PC85, PC37, PC62, PC27, PC130, PC16, PC31, PC56"
     ]
    }
   ],
   "source": [
    "Y_pred = xgboost_test(classifier = classifier_trained,X = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "96bb88d3-6031-4e56-b62a-83b8edf45465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Gender</th>\n",
       "      <th>Predicted_ADHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_Gender  Predicted_ADHD\n",
       "0                 1               0\n",
       "1                 0               0"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "4ed8f95c-4a9a-4fb2-b47e-8529aef96933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 2)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "93ca262a-0a71-44f4-af18-855d63c5e293",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_final = pd.DataFrame()\n",
    "Y_pred_final.insert(0, 'participant_id' , df_categorical_test['participant_id'])\n",
    "Y_pred_final.insert(1, 'ADHD_Outcome' , Y_pred['Predicted_ADHD'])\n",
    "Y_pred_final.insert(2, 'Sex_F' , Y_pred['Predicted_Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "a392e5c0-f9bc-4746-9fc1-e6895e06109f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 3)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "1c0aa8d6-5ce2-4e11-80c2-4471d12e3d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>ADHD_Outcome</th>\n",
       "      <th>Sex_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cfwaf5FX7jWK</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhGrzmvA3Hjq</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  ADHD_Outcome  Sex_F\n",
       "0   Cfwaf5FX7jWK             0      1\n",
       "1   vhGrzmvA3Hjq             0      0"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "29845107-9c68-41d6-9add-3cbed2aa2e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_final.to_excel('output.xlsx', sheet_name='Sheet1', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae74cb0-c109-4b0b-8e04-c04410ae45bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
