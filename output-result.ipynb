{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e92e839a-d375-4991-9632-13955346affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import xlsxwriter\n",
    "import os\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'notebook'\n",
    "import plotly.express as px\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# @changes from inna\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91584b18-4524-49a0-adbc-27cd5120e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folderPathTrain, folderPathTest):\n",
    "    print('load new files')\n",
    "    df_categorical = pd.read_excel(f'{folderPathTrain}/TRAIN_CATEGORICAL_METADATA_new.xlsx')\n",
    "    df_matrices = pd.read_csv(f'{folderPathTrain}/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv')\n",
    "    df_quant = pd.read_excel(f'{folderPathTrain}/TRAIN_QUANTITATIVE_METADATA_new.xlsx')\n",
    "    df_solutions = pd.read_excel(f'{folderPathTrain}/TRAINING_SOLUTIONS.xlsx')  \n",
    "    print('load test files')\n",
    "    df_categorical_test = pd.read_excel(f'{folderPathTest}/TEST_CATEGORICAL.xlsx')\n",
    "    df_matrices_test = pd.read_csv(f'{folderPathTest}/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv')\n",
    "    df_quant_test = pd.read_excel(f'{folderPathTest}/TEST_QUANTITATIVE_METADATA.xlsx')\n",
    "    return df_categorical,df_matrices,df_quant,df_solutions,df_categorical_test,df_matrices_test,df_quant_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e040883f-7790-4bfe-9e3e-97075fed55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_data(categorical,matrices,quantitative,solutions=None):\n",
    "    print('joining data frames')\n",
    "    cat_quant = pd.merge(categorical, quantitative , on ='participant_id', how ='inner')\n",
    "    cat_quant_mat = pd.merge(cat_quant, matrices , on ='participant_id', how ='inner')\n",
    "    if isinstance(solutions, pd.DataFrame):\n",
    "        cat_quant_mat_sols = pd.merge(cat_quant_mat, solutions , on ='participant_id', how ='inner')\n",
    "        return cat_quant_mat_sols\n",
    "    else:    \n",
    "        return cat_quant_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e091d34b-b925-4622-9995-73a2eff9ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_classifer(objective = 'binary:logistic', max_depth=5,learning_rate=0.1,n_estimators=100):\n",
    "    print('xgboost_classifer')\n",
    "    # Initialize the base classifier\n",
    "    classifier = XGBClassifier(objective=objective, \\\n",
    "                               n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth)\n",
    "    multioutput_classifier = MultiOutputClassifier(classifier)\n",
    "    return multioutput_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "703bef88-dd2d-4dfd-b0dc-900b2f7f0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,X_test):\n",
    "    print('predict with the model')\n",
    "    X_test_data  = X_test.drop(columns = ['participant_id'] )\n",
    "    y_pred = model.predict(X_test_data)\n",
    "    predictions_df = pd.DataFrame(\n",
    "        y_pred,\n",
    "        columns=['Predicted_Gender', 'Predicted_ADHD']\n",
    "    )\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c685473c-278b-46cd-96d6-d551b59ed902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(y_test,y_pred):\n",
    "    print('calculate score with prediction vs true values')\n",
    "    y_test_results  = y_test.drop(columns = ['participant_id'] )\n",
    "    accuracy = accuracy_score(y_test_results, y_pred)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6fde7e0-0a6f-4792-acfe-5da22cedf397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_data(X,Y):\n",
    "    print('split the train and test data')\n",
    "    X_train_data, X_test_data, y_train_data, y_test_data = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "    return X_train_data, X_test_data, y_train_data, y_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2f1be46-f7fc-4b14-9f48-e3bd237e6c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_output_accuracy(y_true, y_pred):\n",
    "    print('multi_output_accuracy')\n",
    "    # Ensure y_true and y_pred are NumPy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    # Compute accuracy for each target variable and return the mean\n",
    "    return np.mean([accuracy_score(y_true[:, i], y_pred[:, i]) for i in range(y_true.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5118ade-a2dc-4205-bceb-211daaf6ee60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cross_validation(X,Y,model):\n",
    "    # Perform cross-validation on the training data\n",
    "    X_train_cv  = X.drop(columns = ['participant_id'] )\n",
    "    y_train_cv  = Y.drop(columns = ['participant_id'] )\n",
    "    # Create a scorer using scikit-learn's make_scorer\n",
    "    multi_output_scorer = make_scorer(multi_output_accuracy)\n",
    "    cv_scores = cross_val_score(model, X_train_cv, y_train_cv, cv=5, scoring=multi_output_scorer)\n",
    "    \n",
    "    # Output the cross-validation results\n",
    "    print(\"Cross-validation scores for each fold:\", cv_scores)\n",
    "    print(\"Mean CV score:\", f'Mean Accuracy: {np.mean(cv_scores) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a2ebed42-c23c-443b-ad4b-c18c54c511fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_matrices_data(df_matrices_new,n_components = 1000):\n",
    "    print('starting pca analysis')\n",
    "    print(df_matrices_new.shape)\n",
    "    df_matrices_for_pca = df_matrices_new.drop(columns = ['participant_id'] )\n",
    "    # PCA df with index preserved as index\n",
    "    \n",
    "    original_index = df_matrices_for_pca.index\n",
    "    \n",
    "    # 1. Standardize the data (excluding the first column)\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(df_matrices_for_pca)\n",
    "    \n",
    "    # 2. Apply PCA\n",
    "    # Start with a smaller number of components for exploration\n",
    "    pca = PCA(n_components=n_components)  # Adjust based on your needs\n",
    "    pca_result = pca.fit_transform(scaled_data)\n",
    "    \n",
    "    # 3. Analyze explained variance\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    cumulative_variance = np.cumsum(explained_variance)\n",
    "    \n",
    "    # 5. Find number of components for desired variance (e.g., 80%)\n",
    "    n_components_80 = np.argmax(cumulative_variance >= 0.8) + 1\n",
    "    print(f\"Number of components needed for 80% variance: {n_components_80}\")\n",
    "    \n",
    "    # 6. Re-run PCA with the optimal number of components\n",
    "    pca_final = PCA(n_components=n_components_80)\n",
    "    pca_result_final = pca_final.fit_transform(scaled_data)\n",
    "    \n",
    "    # 7. Create a DataFrame with the PCA results\n",
    "    pca_df = pd.DataFrame(\n",
    "        data=pca_result_final,\n",
    "        columns=[f'PC{i+1}' for i in range(n_components_80)],\n",
    "        index=original_index\n",
    "    )\n",
    "\n",
    "    # 8 \n",
    "    pca_df['participant_id'] = df_matrices_new['participant_id']\n",
    "    \n",
    "    return pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d493e54b-c66d-4853-be1a-fe54e93d79bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_quant_data(df_quant_new):\n",
    "    print('starting quant data scaling')\n",
    "    df_quant_scaled_dropped = df_quant_new.drop(columns = ['participant_id'] )\n",
    "    df_quant_scaled_dropped = pd.DataFrame(df_quant_scaled_dropped)\n",
    "    scaler = StandardScaler()\n",
    "    df_quant_scaled = scaler.fit_transform(df_quant_scaled_dropped)\n",
    "    df_quant_scaled = pd.DataFrame(df_quant_scaled)\n",
    "    df_quant_scaled['participant_id'] = df_quant_new['participant_id']\n",
    "\n",
    "    #select specific columns only for classifier\n",
    "    df_quant_scaled_selected = df_quant_scaled.iloc[:,4:]\n",
    "    return df_quant_scaled_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "02fb1674-717c-4fc9-acb5-01dd4eb46f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_categorical_data(df_categorical_new):\n",
    "    print('starting categorical data encoding')\n",
    "    # One-Hot Encoding (nominal)\n",
    "    # encoder with fixed categoried added for fixing unknown data in train vs test\n",
    "    onehot_encoder = OneHotEncoder(categories = [[0,1,2,3]], handle_unknown='ignore', sparse_output=False, drop='first') #drop first to prevent multicollinearity\n",
    "    #nominal_cols = ['MRI_Track_Scan_Location', 'Basic_Demos_Study_Site', 'PreInt_Demos_Fam_Child_Race', 'PreInt_Demos_Fam_Child_Ethnicity']\n",
    "    nominal_cols = ['PreInt_Demos_Fam_Child_Ethnicity']\n",
    "\n",
    "    \n",
    "    onehot_encoded = onehot_encoder.fit_transform(df_categorical_new[nominal_cols])\n",
    "    onehot_df = pd.DataFrame(onehot_encoded, columns=onehot_encoder.get_feature_names_out(nominal_cols))\n",
    "    encoded_df = pd.concat([df_categorical_new, onehot_df], axis=1)\n",
    "    encoded_df = encoded_df.drop(nominal_cols, axis=1)\n",
    "    \n",
    "    onehot_encoder = OneHotEncoder(categories = [[0,1,2,3,4,5,6,7,8,9,10,11]], handle_unknown='ignore', sparse_output=False, drop='first') #drop first to prevent multicollinearity\n",
    "    nominal_cols = ['PreInt_Demos_Fam_Child_Race']\n",
    "    onehot_encoded = onehot_encoder.fit_transform(df_categorical_new[nominal_cols])\n",
    "    onehot_df = pd.DataFrame(onehot_encoded, columns=onehot_encoder.get_feature_names_out(nominal_cols))\n",
    "    encoded_df = pd.concat([encoded_df, onehot_df], axis=1)\n",
    "    encoded_df = encoded_df.drop(nominal_cols, axis=1)    \n",
    "\n",
    "    onehot_encoder = OneHotEncoder(categories = [[0,1,2,3,4]], handle_unknown='ignore', sparse_output=False, drop='first') #drop first to prevent multicollinearity\n",
    "    nominal_cols = ['MRI_Track_Scan_Location']\n",
    "    onehot_encoded = onehot_encoder.fit_transform(df_categorical_new[nominal_cols])\n",
    "    onehot_df = pd.DataFrame(onehot_encoded, columns=onehot_encoder.get_feature_names_out(nominal_cols))\n",
    "    encoded_df = pd.concat([encoded_df, onehot_df], axis=1)\n",
    "    encoded_df = encoded_df.drop(nominal_cols, axis=1)  \n",
    "    \n",
    "    # Handle NaN and 0.0 values (imputation example)\n",
    "    encoded_df['Barratt_Barratt_P1_Edu'] = encoded_df['Barratt_Barratt_P1_Edu'].fillna(encoded_df['Barratt_Barratt_P1_Edu'].median())\n",
    "    encoded_df['Barratt_Barratt_P2_Edu'] = encoded_df['Barratt_Barratt_P2_Edu'].fillna(encoded_df['Barratt_Barratt_P2_Edu'].median())\n",
    "    \n",
    "    encoded_df['Barratt_Barratt_P1_Edu'] = encoded_df['Barratt_Barratt_P1_Edu'].replace(0.0, encoded_df['Barratt_Barratt_P1_Edu'].median())\n",
    "    encoded_df['Barratt_Barratt_P2_Edu'] = encoded_df['Barratt_Barratt_P2_Edu'].replace(0.0, encoded_df['Barratt_Barratt_P2_Edu'].median())\n",
    "\n",
    "    # Ordinal Encoding (ordinal)\n",
    "    ordinal_encoder = OrdinalEncoder(categories=[[ 3, 6, 9, 12, 15, 18, 21],[ 3, 6, 9, 12, 15, 18, 21] ])\n",
    "    ordinal_cols = ['Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P2_Edu']\n",
    "    encoded_df[ordinal_cols] = ordinal_encoder.fit_transform(encoded_df[ordinal_cols])\n",
    "\n",
    "    # Handle NaN and 0.0 values (imputation example)\n",
    "    encoded_df['Barratt_Barratt_P1_Occ'] = encoded_df['Barratt_Barratt_P1_Occ'].fillna(encoded_df['Barratt_Barratt_P1_Occ'].median())\n",
    "    encoded_df['Barratt_Barratt_P2_Occ'] = encoded_df['Barratt_Barratt_P2_Occ'].fillna(encoded_df['Barratt_Barratt_P2_Occ'].median())\n",
    "    encoded_df['Barratt_Barratt_P1_Occ'] = encoded_df['Barratt_Barratt_P1_Occ'].replace(0.0, encoded_df['Barratt_Barratt_P1_Occ'].median())\n",
    "    encoded_df['Barratt_Barratt_P2_Occ'] = encoded_df['Barratt_Barratt_P2_Occ'].replace(0.0, encoded_df['Barratt_Barratt_P2_Occ'].median())\n",
    "    \n",
    "    # Ordinal Encoding (ordinal)\n",
    "    ordinal_encoder = OrdinalEncoder(categories=[[0, 5, 10, 15, 20, 25, 30, 35, 40, 45], [0, 5, 10, 15, 20, 25, 30, 35, 40, 45]])\n",
    "    ordinal_cols = ['Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Occ']\n",
    "    encoded_df[ordinal_cols] = ordinal_encoder.fit_transform(encoded_df[ordinal_cols])\n",
    "\n",
    "    encoded_df_modified = encoded_df.drop(columns = ['Basic_Demos_Enroll_Year'])\n",
    "    return encoded_df_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7277fc20-0e72-40d7-8b8e-c3cbec6adf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_train(X = None, Y =None,max_depth= None,learning_rate = None,n_estimators = None):\n",
    "    print('starting training')\n",
    "    print('setting tuning params')\n",
    "    classifier = xgboost_classifer(max_depth=max_depth,learning_rate=learning_rate,n_estimators=n_estimators)\n",
    "    print('splitting to test and train')\n",
    "    X_train_data, X_test_data, y_train_data, y_test_data = split_train_data(X, Y)\n",
    "    \n",
    "    print('training the model')\n",
    "    X_train  = X_train_data.drop(columns = ['participant_id'] )\n",
    "    y_train  = y_train_data.drop(columns = ['participant_id'] )\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    print('setting cross validation classifier with tuning params')\n",
    "    classifier_cv = xgboost_classifer(max_depth=max_depth,learning_rate=learning_rate,n_estimators=n_estimators)\n",
    "    print('start cross validation')\n",
    "    do_cross_validation(X,Y,classifier_cv)\n",
    "    \n",
    "    print('check accuracy')\n",
    "    y_pred = predict(classifier,X_test_data)\n",
    "    print('calculate score')\n",
    "    accuracy = calculate_score(y_test_data,y_pred)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb7b6290-0c8a-4e49-92dc-9f1e7b43e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_test(classifier = None,X = None):\n",
    "    print('start testing')\n",
    "    Y = predict(classifier,X)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c85c6-d929-40f6-b84e-444e006dff0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ebf7e6-cec8-4b2f-8e46-bb4735d36503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eaf6668-5462-4f26-a954-441a810fc145",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2fc71f50-a4cf-4da3-b432-6bd5735c5d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load new files\n",
      "load test files\n"
     ]
    }
   ],
   "source": [
    "folderPathTrain, folderPathTest = 'Datafiles/TRAIN_NEW/' , 'Datafiles/TEST/'\n",
    "df_categorical_train,df_matrices_train,df_quant_train,df_solutions_train,df_categorical_test,df_matrices_test,df_quant_test = load_data(folderPathTrain, folderPathTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "692f0a49-d8ba-45ca-9399-be5c62be30e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting pca analysis\n",
      "(1213, 19901)\n",
      "Number of components needed for 80% variance: 1\n",
      "starting quant data scaling\n",
      "starting categorical data encoding\n"
     ]
    }
   ],
   "source": [
    "pca_df_train = transform_matrices_data(df_matrices_train,n_components = 200)\n",
    "quant_df_train = transform_quant_data(df_quant_train)\n",
    "cat_df_train = transform_categorical_data(df_categorical_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "7460ff98-62e3-46da-8457-5cc1faffd4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joining data frames\n"
     ]
    }
   ],
   "source": [
    "# using df_matrices_train instead of pca_df_train\n",
    "joined_training_data = join_data(cat_df_train,df_matrices_train,quant_df_train,df_solutions_train)\n",
    "X = joined_training_data.drop(columns = ['ADHD_Outcome','Sex_F'] )\n",
    "Y = joined_training_data[['participant_id','ADHD_Outcome','Sex_F']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "5e98fd11-ac76-4320-aa9d-cf38c73373c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1213, 19937)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "a4b1e837-581f-4a52-92f0-e91ceb493560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "participant_id    1213\n",
       "ADHD_Outcome      1213\n",
       "Sex_F             1213\n",
       "dtype: int64"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "d41c5437-55b9-4663-a914-93fab0edfc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "setting tuning params\n",
      "xgboost_classifer\n",
      "splitting to test and train\n",
      "split the train and test data\n",
      "training the model\n",
      "setting cross validation classifier with tuning params\n",
      "xgboost_classifer\n",
      "start cross validation\n",
      "multi_output_accuracy\n",
      "multi_output_accuracy\n",
      "multi_output_accuracy\n",
      "multi_output_accuracy\n",
      "multi_output_accuracy\n",
      "Cross-validation scores for each fold: [0.73045267 0.76131687 0.70576132 0.74586777 0.7231405 ]\n",
      "Mean CV score: Mean Accuracy: 73.33%\n",
      "check accuracy\n",
      "predict with the model\n",
      "calculate score\n",
      "calculate score with prediction vs true values\n",
      "Accuracy: 59.26%\n"
     ]
    }
   ],
   "source": [
    "classifier_trained = xgboost_train(X = X, Y =Y,max_depth= 5,learning_rate = 0.1,n_estimators = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84a825c-de80-427c-b688-ea04164e758a",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "d3285f3f-4ffa-4db4-96d9-0bc47f1360c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 19901)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matrices_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "a484a302-d7d4-4810-82ea-9640edef33d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 19)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quant_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "be5c34f8-5c37-4795-9fe0-a613971e1d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 10)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categorical_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a64d72b6-5ec5-430a-ab40-224140504761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting pca analysis\n",
      "(304, 19901)\n",
      "Number of components needed for 80% variance: 162\n",
      "starting quant data scaling\n",
      "starting categorical data encoding\n"
     ]
    }
   ],
   "source": [
    "pca_df_test = transform_matrices_data(df_matrices_test,n_components = 200)\n",
    "quant_df_test = transform_quant_data(df_quant_test)\n",
    "cat_df_test = transform_categorical_data(df_categorical_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "827c6d50-c3ab-4d27-970a-c95d09512d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "49fdbb32-b93b-405b-bf98-96858ad89aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_test.rename(columns={'MRI_Track_Scan_Location_1': 'MRI_Track_Scan_Location_1.0'}, inplace=True)\n",
    "cat_df_test.rename(columns={'MRI_Track_Scan_Location_2': 'MRI_Track_Scan_Location_2.0'}, inplace=True)\n",
    "cat_df_test.rename(columns={'MRI_Track_Scan_Location_3': 'MRI_Track_Scan_Location_3.0'}, inplace=True)\n",
    "cat_df_test.rename(columns={'MRI_Track_Scan_Location_4': 'MRI_Track_Scan_Location_4.0'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "7be0eb8f-c52a-46e0-a697-d6aac72251fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joining data frames\n"
     ]
    }
   ],
   "source": [
    "# using df_matrices_new instead of pca_df_test\n",
    "X_test = join_data(cat_df_test,df_matrices_test,quant_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "9ad12fe9-7577-4931-bf76-7a6a8a981f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "6ee29f46-acc1-474a-ae21-6aecae707834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "8e639dd0-df95-427c-b01f-3ebf85648bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "b0888fed-0526-4d0b-b085-68c68b28cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "4b2451c2-e21b-4e7c-b58d-37bf5a267006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_matrices_new.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "8a1a7e23-8139-4f98-9fea-09e70136d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_matrices_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e58313-13d7-4354-8c56-e5c851211848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "ef39d740-47d2-4f38-9cb6-bf7df02c1078",
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = set(list(X.columns))\n",
    "set2 = set(list(X_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e46e2c-e2e5-4792-a223-819be0e28ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "7ab1e45e-0474-41f1-8025-de5d5af59d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements in list1 but not in list2: []\n"
     ]
    }
   ],
   "source": [
    "difference1 = list(set1 - set2)\n",
    "print(f\"Elements in list1 but not in list2: {difference1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "0ee2d2b6-4c1c-4ced-a71e-622c712177e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca_df_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "254b0704-cdae-41d2-abbd-60620ff75f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca_df_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "6bb19c53-03a0-46c7-8b2a-22c68ad33deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start testing\n",
      "predict with the model\n"
     ]
    }
   ],
   "source": [
    "Y_pred = xgboost_test(classifier = classifier_trained,X = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "96bb88d3-6031-4e56-b62a-83b8edf45465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Gender</th>\n",
       "      <th>Predicted_ADHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_Gender  Predicted_ADHD\n",
       "0                 1               0\n",
       "1                 0               0"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "4ed8f95c-4a9a-4fb2-b47e-8529aef96933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 2)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "93ca262a-0a71-44f4-af18-855d63c5e293",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_final = pd.DataFrame()\n",
    "Y_pred_final.insert(0, 'participant_id' , df_categorical_test['participant_id'])\n",
    "Y_pred_final.insert(1, 'ADHD_Outcome' , Y_pred['Predicted_ADHD'])\n",
    "Y_pred_final.insert(2, 'Sex_F' , Y_pred['Predicted_Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "a392e5c0-f9bc-4746-9fc1-e6895e06109f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 3)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "1c0aa8d6-5ce2-4e11-80c2-4471d12e3d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>ADHD_Outcome</th>\n",
       "      <th>Sex_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cfwaf5FX7jWK</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhGrzmvA3Hjq</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  participant_id  ADHD_Outcome  Sex_F\n",
       "0   Cfwaf5FX7jWK             0      1\n",
       "1   vhGrzmvA3Hjq             0      0"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "29845107-9c68-41d6-9add-3cbed2aa2e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_final.to_excel('output.xlsx', sheet_name='Sheet1', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae74cb0-c109-4b0b-8e04-c04410ae45bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
